{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation of DeeSse simulations\n",
    "\n",
    "We have a synthetic dataset with 100 facies observations (encoded 0 or 1). We are going to use cross-validation approach to find the most suitable training image among three candidate TIs (we will call them A, B, C). We will also identify the what number of nearest neighbors should be used in order to get a best match with the data.\n",
    "\n",
    "We will use 5-fold cross-validation as implemented in the scikit-learn library. DeesseEstimator class has been implemented in a way that it is a valid estimator object and can be supplied to model_selection tools of scikit-learn. Quadratic scoring rule is also implemented in the geone package. We are going to use 5-fold stratified cross-validation with data shuffling and grid search cross-validation to check all combinations of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from geone.img import readImageGslib\n",
    "from geone.gslib import read\n",
    "from geone.imgplot import drawImage2D\n",
    "from geone.deesseinterface import DeesseEstimator\n",
    "from geone.cv_metrics import brier_score, zero_one_score, balanced_linear_score, SkillScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'cv_data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "\n",
    "We have a classical gslib file with a point set and facies observations. We can load it to a dictionary of arrays, and then conveniently to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file to a dictionary of arrays\n",
    "observations = read(DATA_DIR+'sample_100.gslib')\n",
    "\n",
    "# and pass it directly to DataFrame constructor\n",
    "df_observations = pd.DataFrame(observations)\n",
    "df_observations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check basic stats of the point set\n",
    "df_observations.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# quick plot of the set\n",
    "df_observations.plot.scatter(x='X', y='Y', c='code_real00000', cmap='cividis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeeSse simulation engine\n",
    "\n",
    "We want to test what DeeSse parameters (including the TI) fit the best our observation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training images using geone\n",
    "ti_A = readImageGslib(DATA_DIR+'A.gslib')\n",
    "ti_B = readImageGslib(DATA_DIR+'B.gslib')\n",
    "ti_C = readImageGslib(DATA_DIR+'C.gslib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw training images using geone\n",
    "drawImage2D(ti_A, categ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawImage2D(ti_B, categ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawImage2D(ti_C, categ=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to set up DeesseEstimator. It takes the same arguements as DeesseInput plus varnames, which denotes variable names which will be attached to the observation set. Each column should have a name (including coordinates). In our case we have X,Y,Z and 'facies'. 'facies' is also the simulated variable. Note that the names which were read to the pandas DataFrame in the previous step do not matter, as only the values are passed to the simulation engine. Therefore we need to attach names to them to have them properly converted (internally) to a conditioning set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the interface for the DeeSse simulation tool\n",
    "deesse_estimator = DeesseEstimator(\n",
    "    varnames = ['X','Y','Z', 'facies'],\n",
    "        nx=100, ny=100, nz=1,     # dimension of the simulation grid (number of cells)\n",
    "        sx=1.0, sy=1.0, sz=1.0,   # cells units in the simulation grid (here are the default values)\n",
    "        ox=0.0, oy=0.0, oz=0.0,   # origin of the simulation grid (here are the default values)\n",
    "        nv=1, varname='facies',   # number of variable(s), name of the variable(s)\n",
    "        nTI=1, TI=ti_A,           # number of TI(s), TI (class dsi.Img)\n",
    "        distanceType=0,           # distance type: proportion of mismatching nodes (categorical var., default)\n",
    "        nneighboringNode=20,      # max. number of neighbors (for the patterns)\n",
    "        distanceThreshold=0.1,    # acceptation threshold (for distance between patterns)\n",
    "        maxScanFraction=0.25,     # max. scanned fraction of the TI (for simulation of each cell)\n",
    "        npostProcessingPathMax=1, # number of post-processing path(s)\n",
    "        seed=20191201,            # seed (initialization of the random number generator)\n",
    "        nrealization=4,           # number of realization(s)\n",
    "        nthreads=4)               # number of threads to use for simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if we properly defined the estimator by running simulate() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run DeeSse and plot results\n",
    "sim = deesse_estimator.simulate()\n",
    "drawImage2D(sim['sim'][0], categ=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation engine\n",
    "\n",
    "Now we are going to set-up cross validation. We will use scorers implemented in geone.cv_metrics module. Then, we will use GridSearchCV method of scikit-learn to evaluate all parameters combinations. We want to make sure that we use stratified cross-validation with data shuffling, therefore we are going to specify explicitly the split (again, by means of scikit-learn's splitter object).\n",
    "\n",
    "Note that we could also use different model_selection tools available form scikit-learn, such as cross_validate, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring functions\n",
    "\n",
    "Scoring functions are implemented in geone. One could also define custom scorers or use functions from scikit-learn but the are not really suitable for probabilistic forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Brier score (quadratic score), zero-one score, balanced linear score\n",
    "# and quadratic skill, zero-one skill scores\n",
    "scoring = {\n",
    "    'brier':brier_score,\n",
    "    'zero_one':zero_one_score,\n",
    "    'linear':balanced_linear_score,\n",
    "    'skill_brier':SkillScore(DummyClassifier(strategy='prior'), 0, brier_score),\n",
    "    'skill_zero_one':SkillScore(DummyClassifier(strategy='prior'), 1, zero_one_score),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitter definition\n",
    "\n",
    "We want to use 5-fold stratified cross-validation on randomly shuffled data. We use splitter implemented in scikit-learn package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratified 5-fold cross-validation with randomly shuffled data\n",
    "cv = StratifiedKFold(n_splits=5,\n",
    "                     shuffle=True,\n",
    "                     random_state=20191201,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model selection tool\n",
    "\n",
    "We are going to evaluate different sets of parameters, therefore it is convenient to use scikit learns's GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate 3 training images and 3 different numbers of neighbors\n",
    "# cross_validator will need to run 9 times DeeSse (simulating nrealizations every time)\n",
    "cross_validator =  GridSearchCV(deesse_estimator,\n",
    "                    param_grid={'TI': [ti_A, ti_B, ti_C],\n",
    "                               'nneighboringNode': [5, 10, 15]},\n",
    "                    scoring=scoring,\n",
    "                    n_jobs=1,\n",
    "                    cv=cv,\n",
    "                    refit=False,\n",
    "                    verbose=0,\n",
    "                    error_score='raise',\n",
    "                    return_train_score=False,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run the cross-validation with our observed data\n",
    "cross_validator.fit(X=df_observations[['X', 'Y', 'Z']],\n",
    "                    y=df_observations['code_real00000'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the results as pandas DataFrame\n",
    "results = pd.DataFrame(cross_validator.cv_results_)\n",
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show three best scores (Brier score)\n",
    "features = ['param_TI', 'param_nneighboringNode',\n",
    "            'mean_test_brier', 'mean_test_zero_one',\n",
    "            'mean_test_linear', 'mean_test_skill_brier', 'mean_test_skill_zero_one']\n",
    "results.sort_values(by='mean_test_brier', ascending=False).head(3)[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training image A has a higher quadratic score and also zero-one score. Therefore, it is probably a more suitable training image for the problem at hand. It is also better to use a bigger number of neighboring nodes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
